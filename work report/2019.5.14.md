# 2019.5.14

## 一、工作安排

一大早收到了老师的回复，重新确认了需要进行的工作内容：

1. 只需要处理Segmentation相关的内容，不需要处理waypoint
2. Segmentation Net不需要重新训练，只需要把训练好的20-class的Net的输出处理成2-class即可

根据老师的回复来看，昨天waypoint部分的猜想和实现都可以先丢到一边不管了，ERFNet也不需要重新再train，现在需要做的工作就只有两个

1. 找到之前ERFNet输出诡异的原因，把ERFNet整合到pipeline中
2. 使用CARLA simulator来验证结果dirving policy的可靠性

## 二、集成ERFNet

### （1）目前遇到的问题

目前的整个流程是这样的：

1. 首先创建一个erfnet model，并load pretrained params：

   ```python
   # train.py
   def execute():
       try:
           ...
           # Set ERFnet for segmentation
           model_erf = ERFNet(20)	# 20 CLASS
           model_erf = torch.nn.DataParallel(model_erf)
           model_erf = model_erf.cuda()        
           
           print("LOAD ERFNet")
           def load_my_state_dict(model, state_dict):  #custom function to load model when not all dict elements
               own_state = model.state_dict()
               for name, param in state_dict.items():
                   if name not in own_state:
                       continue
                   own_state[name].copy_(param)
               return model
           
           model_erf = load_my_state_dict(model_erf, torch.load(os.path.join('trained_models/erfnet_pretrained.pth')))
           model_erf.eval()
           print ("ERFNet and weights LOADED successfully")
           ...
           for data in data_loader:
               ...
   ```

2. 然后在MAIN LOOP中，调用`rgb2seg`将`data['rgb']`处理为segmentation：

   ```python
   # before
   branches = model(torch.squeeze(data['rgb'].cuda()),
                                dataset.extract_inputs(data).cuda())
   
   ###########################################################################################
   
   # after
   rgbs = data['rgb']
   seg = rgb2seg(rgbs, model_erf)
   branches = model(torch.squeeze(seg.cuda()),
                                dataset.extract_inputs(data).cuda())
   ```

3. 使用的rgb2seg函数为：

   ```python
   def rgb2seg(rgbs, model):
       for inputs in rgbs:
           with torch.no_grad():
               outputs = model(inputs)
   
           label = outputs[0].max(0)[1].byte().cpu().data
   		...
           tmp.append(label)
       
       tmp = torch.stack(tmp)
       return tmp
   ```

   感觉逻辑上没有什么问题，但是把label输出来看，就会发现要么全是0，要么就是两三个数字交替，很显然这样的输出是错误的，现在debug就有两个可能性：

   1. 这个pretrained model本身有问题
   2. 我的调用逻辑有问题

### （2）Debug经历

#### 1. 检验pretrained model的正确性

在和实验室的学长交流之后，拟定了如下的ERFNet debug计划：

1. 在cityscapes dataset上evaluate pretrained ERFNet，如果效果可以，到2
2. 把CoIL dataset中的图片放大到512*1024来eval，如果效果可以，到3
3. 使用原始尺寸的CoIL dataset中的图片来eval，如果效果可以，说明pretrained ERFNet没有问题

使用`erfnet/eval/eval_cityscapes_color.py`测试效果如下：

- $512*1024$ cityscape

  ![](img/city-512_1024.jpg)

- $512*1024$ coil

  ![](img/coil-512_1024.jpg)

- $88*200$ coil

  ![](img/coil-88_200.jpg)

从eval的结果来看：

1. pretrained ERFNet没有问题
2. 对原始尺寸的coil图片进行分割比把它插值放大的结果好很多，所以集成时不需要对rgb的尺寸进行处理

#### 2. 找到之前方法中的错误

##### [猜想1] 不能直接使用data['rgb']，需要针对ERFNet进行img预处理

观察`erfnet_pytorch/eval/dataset.py`的代码，根据传入的方法对数据进行transform：

```python
def __init__(self, root, input_transform=None, target_transform=None):
        self.images_root = os.path.join(root, 'CoILTrain/')

        self.filenames = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(self.images_root)) for f in fn if is_image(f)]
        self.filenames.sort()

        print("filnames size:", len(self.filenames))

        self.input_transform = input_transform
        self.target_transform = target_transform
```

但是这个传入的transform其实只是简单进行了resize和to tensor

```python
input_transform_cityscapes = Compose([
    Resize((512,1024),Image.BILINEAR),
    ToTensor(),
    #Normalize([.485, .456, .406], [.229, .224, .225]),
])
```

##### [猜想2] 将model作为参数传递，在调用的时候会有问题

为了检测是不是被model当作参数传递会有问题，我改写了`rgb2seg`：

```python
def rgb2seg(rgb_names):
    model = ERFNet(NUM_CLASSES)

    model = torch.nn.DataParallel(model)
    model = model.cuda()
     
    # Set ERFnet for segmentation
    model = load_my_state_dict(model, torch.load(os.path.join('trained_models/erfnet_pretrained.pth')))
    model.eval()
    print ("ERFNet and weights LOADED successfully")

    loader = DataLoader(CoIL(rgb_names, input_transform_cityscapes, target_transform_cityscapes),
        num_workers=number_of_workers, batch_size=1, shuffle=False)

    tmp = []
    for step, (images, labels, filename, filenameGt) in enumerate(loader):
        # images = images.cuda()

        inputs = Variable(images)
		with torch.no_grad():
            outputs = model(inputs)

        label = outputs[0].max(0)[1].byte().cpu().data
        tmp.append(label)
    
    tmp = torch.stack(tmp)
    print(tmp.shape)
    return tmp
```

果然，这样输出就是正确的。。。终于找到问题所在了

### （3） 新的实现

开始的时候按照erfnet_pytorch中的写法，对batch中的rgb逐个处理：

```python
	# seg one by one
    seg_road = []
    seg_not_road = []
    i = 0
    for inputs in rgbs:
        inputs = inputs.unsqueeze(0)
        with torch.no_grad():
            outputs = model_erf(inputs)

        label = outputs[0].max(0)[1].byte().cpu().data

        road = (label == 0)
        not_road = (label != 0)
        seg_road.append(road)
        seg_not_road.append(not_road)   
        
	seg_road = torch.stack(seg_road)
    seg_not_road = torch.stack(seg_not_road)
    seg = torch.stack([seg_road,seg_not_road]).transpose(0,1).float()
```

这样能运行，但是速度很慢，就改用了批处理的方法，速度快了很多

```python
	# seg batch
    with torch.no_grad():
        outputs = model_erf(rgbs)

    labels = outputs.max(1)[1].byte().cpu().data

    seg_road = (labels==0)
    seg_not_road = (labels!=0)
    seg = torch.stack((seg_road,seg_not_road),1).float()
```

对第一个batch的分割结果做了可视化处理输出到/savecolor中，显示如下，右边的亮色部分代表左边的road（class 0）

![](img/6.png)

## 三、结果

到目前为止

- train和validate已经可以在更改后的网络中跑通了
- drive部分由于服务器的Ubuntu版本问题，无法安装docker CE，所以暂时还没有成功运行，打算明天换一下服务器试试看